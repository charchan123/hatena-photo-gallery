import os
import json
from bs4 import BeautifulSoup
import html

OUTPUT_DIR = "output"
CACHE_DIR = "cache"
DESC_CACHE_FILE = os.path.join(CACHE_DIR, "description-cache.json")

def rebuild_description_cache():
    os.makedirs(CACHE_DIR, exist_ok=True)
    cache = {}

    # output/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã™ã¹ã¦ã® .html ã‚’èµ°æŸ»
    for filename in os.listdir(OUTPUT_DIR):
        if not filename.endswith(".html"):
            continue

        path = os.path.join(OUTPUT_DIR, filename)
        with open(path, encoding="utf-8") as f:
            soup = BeautifulSoup(f, "html.parser")

        # info-card â†’ <h3> ãŒã‚­ãƒã‚³å
        card = soup.find("div", class_="info-card")
        if not card:
            continue

        h3 = card.find("h3")
        if not h3:
            continue
        name = h3.get_text(strip=True)

        # <p> å…¨éƒ¨ã¤ãªã’ã¦èª¬æ˜æ–‡
        paragraphs = [p.get_text("\n", strip=True) for p in card.find_all("p")]
        desc = "\n".join(paragraphs).strip()

        if name and desc:
            cache[name] = desc
            print(f"âœ” è¿½åŠ : {name}")

    # JSON ã«ä¿å­˜
    with open(DESC_CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump(cache, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ‰ å®Œäº†ï¼ {len(cache)} ä»¶ã®èª¬æ˜æ–‡ã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŒ–ã—ã¾ã—ãŸ")
    print(f"â†’ {DESC_CACHE_FILE}")

if __name__ == "__main__":
    rebuild_description_cache()
