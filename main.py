import os
import glob
import json
import requests
from bs4 import BeautifulSoup
import xml.etree.ElementTree as ET
import re
import html
import piexif

# ===========================
# è¿½åŠ ï¼šEXIFæ–‡å­—ã‚¯ãƒªãƒ¼ãƒ³é–¢æ•°
# ===========================
def clean_exif_str(s):
    if not s:
        return ""
    s = s.replace("\x00", "")              # NULLæ–‡å­—é™¤å»
    s = re.sub(r"[ï¿½]+", "", s)             # æ–‡å­—åŒ–ã‘é™¤å»
    s = s.strip()
    return s

# ====== è¨­å®š ======
HATENA_USER = os.getenv("HATENA_USER")
HATENA_BLOG_ID = os.getenv("HATENA_BLOG_ID")
HATENA_API_KEY = os.getenv("HATENA_API_KEY")

if not all([HATENA_USER, HATENA_BLOG_ID, HATENA_API_KEY]):
    raise EnvironmentError(
        "ç’°å¢ƒå¤‰æ•°ãŒæœªè¨­å®šã§ã™ã€‚HATENA_USER, HATENA_BLOG_ID, HATENA_API_KEY ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
    )

ARTICLES_DIR = "articles"
OUTPUT_DIR = "output"

# ====== EXIF ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š ======
CACHE_DIR = "cache"
CACHE_FILE = os.path.join(CACHE_DIR, "exif-cache.json")

# ====== API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ======
ATOM_ENDPOINT = f"https://blog.hatena.ne.jp/{HATENA_USER}/{HATENA_BLOG_ID}/atom/entry"
AUTH = (HATENA_USER, HATENA_API_KEY)
HEADERS = {}

AIUO_GROUPS = {
    "ã‚è¡Œ": list("ã‚ã„ã†ãˆãŠã‚¢ã‚¤ã‚¦ã‚¨ã‚ª"),
    "ã‹è¡Œ": list("ã‹ããã‘ã“ã‚«ã‚­ã‚¯ã‚±ã‚³ãŒããã’ã”ã‚¬ã‚®ã‚°ã‚²ã‚´"),
    "ã•è¡Œ": list("ã•ã—ã™ã›ãã‚µã‚·ã‚¹ã‚»ã‚½ã–ã˜ãšãœãã‚¶ã‚¸ã‚ºã‚¼ã‚¾"),
    "ãŸè¡Œ": list("ãŸã¡ã¤ã¦ã¨ã‚¿ãƒãƒ„ãƒ†ãƒˆã ã¢ã¥ã§ã©ãƒ€ãƒ‚ãƒ…ãƒ‡ãƒ‰"),
    "ãªè¡Œ": list("ãªã«ã¬ã­ã®ãƒŠãƒ‹ãƒŒãƒãƒ"),
    "ã¯è¡Œ": list("ã¯ã²ãµã¸ã»ãƒãƒ’ãƒ•ãƒ˜ãƒ›ã°ã³ã¶ã¹ã¼ãƒãƒ“ãƒ–ãƒ™ãƒœã±ã´ã·ãºã½ãƒ‘ãƒ”ãƒ—ãƒšãƒ"),
    "ã¾è¡Œ": list("ã¾ã¿ã‚€ã‚ã‚‚ãƒãƒŸãƒ ãƒ¡ãƒ¢"),
    "ã‚„è¡Œ": list("ã‚„ã‚†ã‚ˆãƒ¤ãƒ¦ãƒ¨"),
    "ã‚‰è¡Œ": list("ã‚‰ã‚Šã‚‹ã‚Œã‚ãƒ©ãƒªãƒ«ãƒ¬ãƒ­"),
    "ã‚è¡Œ": list("ã‚ã‚’ã‚“ãƒ¯ãƒ²ãƒ³"),
}

# ====== å…±é€šã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆï¼‹èª¬æ˜ã‚«ãƒ¼ãƒ‰CSSè¿½åŠ ï¼‰ ======
STYLE_TAG = """<style>
html, body {
  margin: 0;
  padding: 0;
  overflow-y: hidden;
}
body {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
  background:#fafafa;
  color:#333;
  padding:16px;
  box-sizing:border-box;
}

.gallery {
  column-count: 2;
  column-gap: 10px;
  max-width: 900px;
  margin: 0 auto;
  visibility: hidden;
}
.gallery a.gallery-item{
  display: block;
  break-inside: avoid;
  margin-bottom: 10px;
  border-radius: 8px;
  overflow: hidden;
}
.gallery img {
  width: 100%;
  height: auto;
  display: block;
  cursor: zoom-in;
  transition: opacity 0.6s ease, transform 0.6s ease;
  opacity: 0;
  transform: translateY(10px);
}
.gallery img.visible {
  opacity: 1;
  transform: translateY(0);
}

@media (max-width: 480px) {
  .gallery { column-count: 1; }
}
</style>

<style>
/* LightGallery ã¨åŒã˜ã‚¹ã‚¿ã‚¤ãƒ«ã®ã‚«ãƒ¡ãƒ©ã‚¢ã‚¤ã‚³ãƒ³ */
.lg-exif-toggle.lg-icon::after {
  content: "";
  width: 22px;
  height: 22px;
  display: block;

  /* Camera ã® SVGï¼ˆLightGallery ã¨åŒã˜ç™½ã„ç·šï¼‰*/
  mask: url("data:image/svg+xml,%3Csvg width='24' height='24' stroke='white' fill='none' stroke-width='2' stroke-linecap='round' stroke-linejoin='round' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='M23 19a2 2 0 0 1-2 2H3a2 2 0 0 1-2-2V7a2 2 0 0 1 2-2h3l2-3h8l2 3h3a2 2 0 0 1 2 2z'/%3E%3Ccircle cx='12' cy='13' r='4'/%3E%3C/svg%3E") no-repeat center;
  background-color: white;
}
</style>
"""

# ====== LightGallery èª­ã¿è¾¼ã¿ã‚¿ã‚° ======
LIGHTGALLERY_TAGS = """
<link rel="stylesheet" href="./lightgallery/lightgallery-bundle.min.css">
<link rel="stylesheet" href="./lightgallery/lg-thumbnail.css">

<script src="./lightgallery/lightgallery.min.js"></script>
<script src="./lightgallery/lg-zoom.min.js"></script>
<script src="./lightgallery/lg-thumbnail.min.js"></script>
"""

# ====== LightGallery ã‚¹ã‚¯ãƒªãƒ—ãƒˆ ======
SCRIPT_TAG = """<script src="https://unpkg.com/imagesloaded@5/imagesloaded.pkgd.min.js"></script>
<script>
document.addEventListener("DOMContentLoaded", () => {

  function sendHeight() {
    const height = document.documentElement.scrollHeight;
    window.parent.postMessage({ type:"setHeight", height }, "*");
  }

  const gallery = document.querySelector(".gallery");
  if (gallery) {
    const fadeObs = new IntersectionObserver(entries=>{
      entries.forEach(e=>{
        if(e.isIntersecting){
          e.target.classList.add("visible");
          fadeObs.unobserve(e.target);
        }
      });
    }, {threshold:0.1});
    gallery.querySelectorAll("img").forEach(img=>fadeObs.observe(img));

    imagesLoaded(gallery, () => {
      gallery.style.visibility="visible";
      sendHeight();

      const lg = lightGallery(gallery, {
        selector: 'a.gallery-item',
        plugins: [lgZoom, lgThumbnail],
        speed: 400,
        download: false,
        zoom: true,
        thumbnail: true
      });

      /* ==================================
         â‘  ã‚µãƒ ãƒã‚¤ãƒ«ã‚¯ãƒªãƒƒã‚¯æ™‚ã«
            å¼·åˆ¶ãƒ•ãƒ«ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ç™ºå‹•
      =================================== */
      gallery.querySelectorAll("a.gallery-item").forEach((a) => {
        a.addEventListener("click", () => {
          const el = document.documentElement;

          if (el.requestFullscreen) el.requestFullscreen();
          else if (el.webkitRequestFullscreen) el.webkitRequestFullscreen();
          else if (el.msRequestFullscreen) el.msRequestFullscreen();
        });
      });

      /* ==================================
         â‘¡ v2ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆé–‰ã˜ã‚‹å‰ï¼‰
      =================================== */
      gallery.addEventListener("lgBeforeClose", () => {
        console.log("ğŸ“¤ å­ï¼šLG before close ç™ºç«");
        if (document.fullscreenElement) {
          document.exitFullscreen().catch(()=>{});
        }
        window.parent.postMessage({ type: "lgClosed" }, "*");
      });

      /* ==================================
         â‘¢ ESC â†’ ãƒ•ãƒ«ã‚¹ã‚¯ãƒªãƒ¼ãƒ³è§£é™¤ â†’ è¦ªã¸é€šçŸ¥
      =================================== */
      document.addEventListener("fullscreenchange", () => {
        if (!document.fullscreenElement) {
          console.log("ğŸ“¤ å­ï¼šfullscreenchangeç™ºç« â†’ è¦ªã« lgClosed ã‚’é€ä¿¡");
          try {
            lg.closeGallery();
            window.parent.postMessage({ type: "lgClosed" }, "*");
          } catch(e) {}
        }
      });
    });
  }

  /* ===========================================
       â˜… ã‚¯ãƒªãƒƒã‚¯åˆ¤å®šã¯ gallery ã®å¤–ã¸ç§»å‹•
       â†’ å…¨ãƒšãƒ¼ã‚¸ã§ scrollToTitle ã‚’é€ä¿¡ã§ãã‚‹
  ============================================ */
  document.addEventListener("click", (e) => {
    const a = e.target.closest("a");
    if (!a) return;

    const txt = a.textContent || "";
    const href = a.getAttribute("href") || "";

    console.log("[iframe] click anchor:", { text: txt, href });

    // 1) ã‚­ãƒã‚³åãƒšãƒ¼ã‚¸ (xxx.html)
    if (href.endsWith(".html")) {
      console.log("[iframe] send scrollToTitle (html link)");
      window.parent.postMessage({ type: "scrollToTitle" }, "*");
      return;
    }

    // 2) ã‚è¡Œã€œã‚è¡Œ
    if (/^(ã‚è¡Œ|ã‹è¡Œ|ã•è¡Œ|ãŸè¡Œ|ãªè¡Œ|ã¯è¡Œ|ã¾è¡Œ|ã‚„è¡Œ|ã‚‰è¡Œ|ã‚è¡Œ)$/.test(txt)) {
      console.log("[iframe] send scrollToTitle (aiuo link)");
      window.parent.postMessage({ type: "scrollToTitle" }, "*");
      return;
    }

    // 3) â† æˆ»ã‚‹
    if (/æˆ»ã‚‹/.test(txt)) {
      console.log("[iframe] send scrollToTitle (back)");
      window.parent.postMessage({ type: "scrollToTitle" }, "*");
      return;
    }
  });

  sendHeight();
  window.addEventListener("load", ()=>{ sendHeight(); setTimeout(sendHeight,800); setTimeout(sendHeight,2000); });
  window.addEventListener("message", e=>{ if(e.data?.type==="requestHeight") sendHeight(); });
  window.addEventListener("resize", sendHeight);
  new MutationObserver(sendHeight).observe(document.body,{childList:true,subtree:true});

});

</script>

<!-- â–¼â–¼â–¼ è¿½åŠ ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼šEXIF ON/OFF åˆ‡æ›¿ â–¼â–¼â–¼ -->
<script>
(function() {

  // LightGallery ã® DOM ãŒæº–å‚™ã§ãã‚‹ã¾ã§å¾…ã¤
  const ready = setInterval(() => {
    const toolbar = document.querySelector(".lg-toolbar");
    const subHtml = document.querySelector(".lg-sub-html");
    if (!toolbar || !subHtml) return;

    clearInterval(ready);

    // =============== â‘  ã‚«ãƒ¡ãƒ©ã‚¢ã‚¤ã‚³ãƒ³è¿½åŠ ï¼ˆæ­£ã—ããƒ„ãƒ¼ãƒ«ãƒãƒ¼ã«ä¸¦ã¹ã‚‹ï¼‰ ===================
    const btn = document.createElement("button");
    btn.className = "lg-icon lg-exif-toggle";
    btn.innerHTML = "ğŸ“·";  // â† ã‚¢ã‚¤ã‚³ãƒ³
    btn.style.cssText = `
      font-size: 22px;
      background: none;
      border: none;
      cursor: pointer;
      margin-left: 8px;
    `;
    toolbar.append(btn);

    // =============== â‘¡ EXIF ã®åˆæœŸçŠ¶æ…‹ï¼ˆLocalStorageï¼‰ ===================
    let visible = localStorage.getItem("mushroom_exif_visible") !== "0";

    function applyExif(show) {
      const htmls = document.querySelectorAll(".lg-sub-html");
      htmls.forEach(el => {
        el.style.display = show ? "block" : "none";
      });

      // é‡è¦ï¼ LightGallery ã«ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå†è¨ˆç®—ã‚’è¦æ±‚
      const evt = new Event("resize");
      window.dispatchEvent(evt);

      localStorage.setItem("mushroom_exif_visible", show ? "1" : "0");
    }

    applyExif(visible);

    // =============== â‘¢ ã‚«ãƒ¡ãƒ©ã‚¢ã‚¤ã‚³ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§ EXIF åˆ‡æ›¿ ===================
    btn.addEventListener("click", () => {
      visible = !visible;
      applyExif(visible);
    });

    // ã‚¹ãƒ©ã‚¤ãƒ‰å¤‰æ›´æ™‚ã«ã‚‚é©ç”¨
    document.addEventListener("lgAfterSlide", () => {
      applyExif(visible);
    });

    // =============== â‘£ ãƒ•ãƒ«ã‚¹ã‚¯ãƒªãƒ¼ãƒ³è§£é™¤å¾Œã®å†ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå¯¾ç­– ===================
    document.addEventListener("fullscreenchange", () => {
      setTimeout(() => {
        const evt2 = new Event("resize");
        window.dispatchEvent(evt2);
      }, 300);
    });

  }, 300);

})();
</script>
<!-- â–²â–²â–² è¿½åŠ ã‚¹ã‚¯ãƒªãƒ—ãƒˆã“ã“ã¾ã§ â–²â–²â–² -->
"""

# ===========================
# EXIF ã‚­ãƒ£ãƒƒã‚·ãƒ¥
# ===========================
def load_exif_cache():
    if not os.path.exists(CACHE_FILE):
        return {}
    try:
        with open(CACHE_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
            if isinstance(data, dict):
                return data
    except Exception:
        pass
    return {}

def save_exif_cache(cache: dict):
    os.makedirs(CACHE_DIR, exist_ok=True)
    with open(CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump(cache, f, ensure_ascii=False, indent=2)

def _rational_to_float(val):
    try:
        if isinstance(val, tuple) and len(val) == 2 and val[1]:
            return val[0] / val[1]
    except Exception:
        pass
    try:
        return float(val)
    except Exception:
        return None

def _exposure_to_str(val):
    if isinstance(val, tuple) and len(val) == 2 and val[1]:
        num, den = val
        return f"{num}/{den}"
    try:
        return str(val)
    except Exception:
        return ""

# ===========================
# EXIF æŠ½å‡º
# ===========================
def extract_exif_from_bytes(jpeg_bytes: bytes):
    try:
        exif_dict = piexif.load(jpeg_bytes)
    except Exception:
        return {}

    zero = exif_dict.get("0th", {})
    exif = exif_dict.get("Exif", {})

    # Model
    model = zero.get(piexif.ImageIFD.Model, b"")
    if isinstance(model, bytes):
        model = clean_exif_str(model.decode(errors="ignore"))
    else:
        model = clean_exif_str(str(model))

    # LensModel
    lens = exif.get(piexif.ExifIFD.LensModel, b"")
    if isinstance(lens, bytes):
        lens = clean_exif_str(lens.decode(errors="ignore"))
    else:
        lens = clean_exif_str(str(lens))

    if "IS" in lens:
        lens = lens.split("IS")[0] + "IS"

    # ISO
    iso = exif.get(piexif.ExifIFD.ISOSpeedRatings) or exif.get(piexif.ExifIFD.ISO)
    if isinstance(iso, (list, tuple)):
        iso = iso[0]
    iso_str = str(iso) if iso is not None else ""

    # Få€¤
    fnum = exif.get(piexif.ExifIFD.FNumber)
    f_str = ""
    fv = _rational_to_float(fnum)
    if fv:
        f_str = f"f/{fv:.1f}"

    # ã‚·ãƒ£ãƒƒã‚¿ãƒ¼ã‚¹ãƒ”ãƒ¼ãƒ‰
    exposure = exif.get(piexif.ExifIFD.ExposureTime)
    exposure_str = _exposure_to_str(exposure)

    # ç„¦ç‚¹è·é›¢
    focal = exif.get(piexif.ExifIFD.FocalLength)
    focal_str = ""
    fv2 = _rational_to_float(focal)
    if fv2:
        if abs(fv2 - round(fv2)) < 0.1:
            focal_str = f"{int(round(fv2))}mm"
        else:
            focal_str = f"{fv2:.1f}mm"

    # æ—¥ä»˜
    dt = exif.get(piexif.ExifIFD.DateTimeOriginal, b"")
    if isinstance(dt, bytes):
        dt = dt.decode(errors="ignore")
    date_str = ""
    if dt:
        parts = dt.split(" ")
        if parts:
            date_str = parts[0].replace(":", "/")

    return {
        "model": model or "",
        "lens": lens or "",
        "iso": iso_str or "",
        "f": f_str or "",
        "exposure": exposure_str or "",
        "focal": focal_str or "",
        "date": date_str or "",
    }

# ===========================
# EXIF ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ§‹ç¯‰
# ===========================
def build_exif_cache(entries, cache: dict):
    os.makedirs(CACHE_DIR, exist_ok=True)

    all_srcs = sorted({e["src"] for e in entries})

    for src in all_srcs:
        if src in cache:
            continue

        print(f"ğŸ” EXIFå–å¾—: {src}")
        exif_data = {}
        try:
            r = requests.get(src, timeout=10)
            if r.status_code == 200:
                exif_data = extract_exif_from_bytes(r.content) or {}
                print(f"  â†ª EXIFå–å¾—OK: {exif_data}")
            else:
                print(f"  â†ª HTTP {r.status_code} â†’ ç©ºãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿å­˜")
        except Exception as e:
            print(f"  â†ª å–å¾—ã‚¨ãƒ©ãƒ¼: {e} â†’ ç©ºãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿å­˜")

        cache[src] = exif_data

    return cache

# ===========================
# ã¯ã¦ãªAPI å…¨è¨˜äº‹å–å¾—
# ===========================
def fetch_hatena_articles_api():
    os.makedirs(ARTICLES_DIR, exist_ok=True)
    print("ğŸ“¡ ã¯ã¦ãªãƒ–ãƒ­ã‚°APIã‹ã‚‰å…¨è¨˜äº‹å–å¾—ä¸­â€¦")
    url = ATOM_ENDPOINT
    count = 0
    while url:
        print(f"ğŸ”— Fetching: {url}")
        r = requests.get(url, auth=AUTH, headers=HEADERS)
        if r.status_code != 200:
            raise RuntimeError(f"âŒ APIå–å¾—å¤±æ•—: {r.status_code} {r.text}")

        root = ET.fromstring(r.text)
        ns = {"atom": "http://www.w3.org/2005/Atom"}
        entries = root.findall("atom:entry", ns)

        for i, entry in enumerate(entries, 1):
            content = entry.find("atom:content", ns)
            if content is None:
                continue
            html_content = content.text or ""
            filename = f"{ARTICLES_DIR}/article_{count+i}.html"
            with open(filename, "w", encoding="utf-8") as f:
                f.write(html_content)
            print(f"âœ… ä¿å­˜å®Œäº†: {filename}")

        count += len(entries)
        next_link = root.find("atom:link[@rel='next']", ns)
        url = next_link.attrib["href"] if next_link is not None else None

    print(f"ğŸ“¦ åˆè¨ˆ {count} ä»¶ã®è¨˜äº‹ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")

# ===========================
# HTML ã‹ã‚‰ç”»åƒæŠ½å‡º
# ===========================
def fetch_images():
    print("ğŸ“‚ HTMLã‹ã‚‰ç”»åƒæŠ½å‡ºä¸­â€¦")
    entries = []

    exclude_patterns = [
        r'ã¯ã¦ãªãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯',
        r'^\d{4}å¹´',
        r'^ã“ã®è¨˜äº‹ã‚’ã¯ã¦ãªãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã«è¿½åŠ $',
        r'^ãƒ¯è¡Œ$',
        r'ã‚­ãƒã‚³ã¨ç”°èˆéŠã³',
    ]

    for html_file in glob.glob(f"{ARTICLES_DIR}/*.html"):
        with open(html_file, encoding="utf-8") as f:
            soup = BeautifulSoup(f, "html.parser")

        body_div = soup.find(class_="entry-body") or soup

        for iframe in body_div.find_all("iframe"):
            title = iframe.get("title", "")
            if any(re.search(p, title) for p in exclude_patterns):
                iframe.decompose()

        for a in body_div.find_all("a"):
            text = a.get_text(strip=True)
            if any(re.search(p, text) for p in exclude_patterns):
                a.decompose()

        imgs = body_div.find_all("img")
        for img in imgs:
            alt = (img.get("alt") or "").strip()
            src = img.get("src")
            if not alt or not src:
                continue
            if any(re.search(p, alt) for p in exclude_patterns):
                continue

            entries.append({"alt": alt, "src": src})

    print(f"ğŸ§© ç”»åƒæ¤œå‡ºæ•°: {len(entries)} æš")
    return entries

# ===========================
# äº”åéŸ³åˆ†é¡
# ===========================
def get_aiuo_group(name):
    if not name:
        return "ãã®ä»–"
    first = name[0]
    for group, chars in AIUO_GROUPS.items():
        if first in chars:
            return group
    return "ãã®ä»–"

# ===========================
# EXIF â†’ caption HTML
# ===========================
def build_caption_html(alt, exif: dict):
    title = html.escape(alt)

    model = exif.get("model") or ""
    lens = exif.get("lens") or ""
    iso = exif.get("iso") or ""
    f = exif.get("f") or ""
    exposure = exif.get("exposure") or ""
    focal = exif.get("focal") or ""
    date = exif.get("date") or ""

    parts = []
    if model:
        parts.append(f"ã‚«ãƒ¡ãƒ©ï¼š{html.escape(model)}")
    if lens:
        parts.append(f"ãƒ¬ãƒ³ã‚ºï¼š{html.escape(lens)}")
    if iso:
        parts.append(f"ISOï¼š{html.escape(iso)}")
    if f:
        parts.append(f"çµã‚Šï¼š{html.escape(f)}")
    if exposure:
        parts.append(f"ã‚·ãƒ£ãƒƒã‚¿ãƒ¼é€Ÿåº¦ï¼š{html.escape(exposure)}")
    if focal:
        parts.append(f"ç„¦ç‚¹è·é›¢ï¼š{html.escape(focal)}")
    if date:
        parts.append(f"æ’®å½±æ—¥ï¼š{html.escape(date)}")

    exif_line = " | ".join(parts)

    html_block = f"""
    <div style='text-align:center;'>
        <div style='font-weight:bold; font-size:1.2em; margin-bottom:6px;'>{title}</div>
        <div style='font-size:0.9em; line-height:1.4;'>{exif_line}</div>
    </div>
    """

    return html.escape(html_block, quote=True)

# ===========================
# ã‚®ãƒ£ãƒ©ãƒªãƒ¼ç”Ÿæˆ
# ===========================
def generate_gallery(entries, exif_cache):
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    grouped = {}
    for e in entries:
        grouped.setdefault(e["alt"], []).append(e["src"])

    group_links = " | ".join([f'<a href="{g}.html">{g}</a>' for g in AIUO_GROUPS.keys()])
    group_links_html = f"<div style='margin-top:40px; text-align:center;'>{group_links}</div>"

    def safe_filename(name):
        name = re.sub(r'[:<>\"|*?\\\\/\\r\\n]', '_', name)
        name = name.strip()
        if not name:
            name = "unnamed"
        return name

    # ---- å„ã‚­ãƒã‚³ãƒšãƒ¼ã‚¸ ----
    for alt, imgs in grouped.items():
        html_parts = []

        # ====== ã‚®ãƒ£ãƒ©ãƒªãƒ¼ ======
        html_parts.append("<div class='gallery'>")
        for src in imgs:
            thumb = src + "?width=300"
            exif = exif_cache.get(src, {}) or {}
            caption_attr = build_caption_html(alt, exif)

            html_parts.append(
                f'<a class="gallery-item" href="{src}" '
                f'data-exthumbimage="{thumb}" '
                f'data-sub-html="{caption_attr}">'
                f'<img src="{src}" alt="{html.escape(alt)}" loading="lazy">'
                f'</a>'
            )

        html_parts.append("</div>")

        html_parts.append("""
        <div style='margin-top:40px; text-align:center;'>
            <a href='javascript:history.back()' style='text-decoration:none;color:#007acc;'>â† æˆ»ã‚‹</a>
        </div>
        """)

        html_parts.append(STYLE_TAG)
        html_parts.append(LIGHTGALLERY_TAGS)
        html_parts.append(SCRIPT_TAG)

        page_html = "".join(html_parts)

        safe = safe_filename(alt)
        with open(f"{OUTPUT_DIR}/{safe}.html", "w", encoding="utf-8") as f:
            f.write(page_html)

    # ---- äº”åéŸ³ãƒšãƒ¼ã‚¸ ----
    aiuo_dict = {k: [] for k in AIUO_GROUPS.keys()}
    for alt in grouped.keys():
        g = get_aiuo_group(alt)
        if g in aiuo_dict:
            aiuo_dict[g].append(alt)

    for g, names in aiuo_dict.items():
        html_parts = []
        html_parts.append(f"<h2>{g}ã®ã‚­ãƒã‚³</h2><ul>")
        for n in sorted(names):
            safe = safe_filename(n)
            html_parts.append(f'<li><a href="{safe}.html">{html.escape(n)}</a></li>')
        html_parts.append("</ul>")
        html_parts.append(group_links_html)
        html_parts.append(STYLE_TAG)
        html_parts.append(LIGHTGALLERY_TAGS)
        html_parts.append(SCRIPT_TAG)

        page_html = "".join(html_parts)

        with open(f"{OUTPUT_DIR}/{safe_filename(g)}.html", "w", encoding="utf-8") as f:
            f.write(page_html)

    # ---- index ----
    index_parts = []
    index_parts.append("<h2>äº”åéŸ³åˆ¥åˆ†é¡</h2><ul>")
    for g in AIUO_GROUPS.keys():
        index_parts.append(f'<li><a href="{safe_filename(g)}.html">{g}</a></li>')
    index_parts.append("</ul>")
    index_parts.append(STYLE_TAG)
    index_parts.append(LIGHTGALLERY_TAGS)
    index_parts.append(SCRIPT_TAG)

    index_html = "".join(index_parts)

    with open(f"{OUTPUT_DIR}/index.html", "w", encoding="utf-8") as f:
        f.write(index_html)

    print("âœ… ã‚®ãƒ£ãƒ©ãƒªãƒ¼ãƒšãƒ¼ã‚¸ç”Ÿæˆå®Œäº†")

# ===========================
# ãƒ¡ã‚¤ãƒ³
# ===========================
if __name__ == "__main__":
    fetch_hatena_articles_api()
    entries = fetch_images()
    if entries:
        exif_cache = load_exif_cache()
        exif_cache = build_exif_cache(entries, exif_cache)
        save_exif_cache(exif_cache)
        generate_gallery(entries, exif_cache)
    else:
        print("âš ï¸ ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
