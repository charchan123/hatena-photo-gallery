import os, glob, time, requests, feedparser
from bs4 import BeautifulSoup

# ====== è¨­å®š ======
HATENA_USER = os.getenv("HATENA_USER", "charchan123")
HATENA_BLOG_ID = os.getenv("HATENA_BLOG_ID", "charchan123.hatenablog.com")

BLOG_RSS_URL = "https://exsudoporus-ruber.hatenablog.jp/rss"
ARTICLES_DIR = "articles"
OUTPUT_DIR = "output"

AIUO_GROUPS = {
    "ã‚è¡Œ": list("ã‚ã„ã†ãˆãŠã‚¢ã‚¤ã‚¦ã‚¨ã‚ª"),
    "ã‹è¡Œ": list("ã‹ããã‘ã“ã‚«ã‚­ã‚¯ã‚±ã‚³ãŒããã’ã”ã‚¬ã‚®ã‚°ã‚²ã‚´"),
    "ã•è¡Œ": list("ã•ã—ã™ã›ãã‚µã‚·ã‚¹ã‚»ã‚½ã–ã˜ãšãœãã‚¶ã‚¸ã‚ºã‚¼ã‚¾"),
    "ãŸè¡Œ": list("ãŸã¡ã¤ã¦ã¨ã‚¿ãƒãƒ„ãƒ†ãƒˆã ã¢ã¥ã§ã©ãƒ€ãƒ‚ãƒ…ãƒ‡ãƒ‰"),
    "ãªè¡Œ": list("ãªã«ã¬ã­ã®ãƒŠãƒ‹ãƒŒãƒãƒ"),
    "ã¯è¡Œ": list("ã¯ã²ãµã¸ã»ãƒãƒ’ãƒ•ãƒ˜ãƒ›ã°ã³ã¶ã¹ã¼ãƒãƒ“ãƒ–ãƒ™ãƒœã±ã´ã·ãºã½ãƒ‘ãƒ”ãƒ—ãƒšãƒ"),
    "ã¾è¡Œ": list("ã¾ã¿ã‚€ã‚ã‚‚ãƒãƒŸãƒ ãƒ¡ãƒ¢"),
    "ã‚„è¡Œ": list("ã‚„ã‚†ã‚ˆãƒ¤ãƒ¦ãƒ¨"),
    "ã‚‰è¡Œ": list("ã‚‰ã‚Šã‚‹ã‚Œã‚ãƒ©ãƒªãƒ«ãƒ¬ãƒ­"),
    "ã‚è¡Œ": list("ã‚ã‚’ã‚“ãƒ¯ãƒ²ãƒ³"),
}

# ====== iframe é«˜ã•è‡ªå‹•èª¿æ•´ ======
SCRIPT_TAG = """
<script>
(function() {
  if (window === window.parent) return;
  const sendHeight = () => {
    const height = document.documentElement.scrollHeight;
    window.parent.postMessage({ type: "setHeight", height }, "*");
  };
  window.addEventListener("load", () => { sendHeight(); setTimeout(sendHeight, 800); });
  window.addEventListener("resize", sendHeight);
  window.addEventListener("popstate", sendHeight);
  window.addEventListener("hashchange", sendHeight);
  const observer = new MutationObserver(() => sendHeight());
  observer.observe(document.body, { childList: true, subtree: true });
  document.querySelectorAll("img").forEach(img => img.addEventListener("load", sendHeight));
  document.addEventListener("click", e => {
    const a = e.target.closest("a");
    if (a && a.getAttribute("href")) setTimeout(sendHeight, 600);
  });
})();
</script>
"""

# ====== ã‚¹ã‚¿ã‚¤ãƒ« + ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³ ======
STYLE_TAG = """
<style>
html, body { margin:0; padding:0; overflow-x:hidden; height:auto!important; }
body {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
  background: #fafafa; color: #333; padding:16px; text-align:left;
}
h2 { font-size:1.4em; margin-bottom:12px; text-align:left; }
ul { list-style:none; padding:0; }
li { margin:6px 0; text-align:left; }
a { color:#007acc; text-decoration:none; }
a:hover { text-decoration:underline; }
.nav { margin-top:24px; font-size:1.1em; line-height:2em; text-align:left; flex-wrap:wrap; }
strong { color:#000; text-decoration:underline; }
.gallery {
  display:grid; grid-template-columns:repeat(auto-fit,minmax(160px,1fr));
  gap:10px; margin-top:20px;
}
.gallery img {
  width:100%; border-radius:8px; opacity:0; transform:translateY(10px);
  transition:opacity 0.6s ease-out, transform 0.6s ease-out;
}
.gallery img.visible { opacity:1; transform:translateY(0); }
@media (max-width:600px) {
  body { padding:12px; } h2 { font-size:1.2em; } .gallery { gap:6px; }
}
</style>
<script>
document.addEventListener("DOMContentLoaded", () => {
  const imgs=document.querySelectorAll(".gallery img");
  const obs=new IntersectionObserver(es=>{
    es.forEach(e=>{if(e.isIntersecting){e.target.classList.add("visible");obs.unobserve(e.target);}});
  },{threshold:0.1});
  imgs.forEach(img=>obs.observe(img));
});
</script>
"""

# ====== ã¯ã¦ãªãƒ–ãƒ­ã‚°ã®è¨˜äº‹ã‚’RSSã‹ã‚‰å–å¾— ======
def fetch_hatena_articles():
    os.makedirs(ARTICLES_DIR, exist_ok=True)
    print(f"ğŸ“° ã¯ã¦ãªãƒ–ãƒ­ã‚°RSSå–å¾—: {BLOG_RSS_URL}")

    feed = feedparser.parse(BLOG_RSS_URL)
    if not feed.entries:
        raise RuntimeError("âŒ RSSãƒ•ã‚£ãƒ¼ãƒ‰ãŒå–å¾—ã§ãã¾ã›ã‚“ã€‚URLã¾ãŸã¯ãƒ–ãƒ­ã‚°ã®å…¬é–‹è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    print(f"ğŸ“¡ {len(feed.entries)}ä»¶ã®è¨˜äº‹ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚")

    for i, entry in enumerate(feed.entries, 1):
        url = entry.link
        print(f"({i}) {url}")
        for retry in range(3):
            try:
                r = requests.get(url, timeout=10)
                if r.status_code == 200:
                    filename = f"{ARTICLES_DIR}/article{i}.html"
                    with open(filename, "w", encoding="utf-8") as f:
                        f.write(r.text)
                    print(f"âœ… ä¿å­˜å®Œäº†: {filename}")
                    break
                else:
                    print(f"âš ï¸ [{r.status_code}] å†è©¦è¡Œ {retry+1}/3")
            except Exception as e:
                print(f"âš ï¸ å–å¾—å¤±æ•—: {e}")
                time.sleep(3)
        else:
            print(f"âŒ æœ€çµ‚çš„ã«å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ: {url}")

# ====== HTMLã‹ã‚‰ç”»åƒã‚’æŠ½å‡º ======
def fetch_images():
    print("ğŸ“‚ HTMLã‹ã‚‰ç”»åƒã‚’æŠ½å‡ºä¸­â€¦")
    entries = []
    html_files = glob.glob(f"{ARTICLES_DIR}/*.html")
    for html_file in html_files:
        with open(html_file, encoding="utf-8") as f:
            soup = BeautifulSoup(f, "html.parser")
            # ãƒ‘ã‚¿ãƒ¼ãƒ³â‘  æ¨™æº–æ§‹é€ 
            entry_content = soup.find("div", class_="entry-content hatenablog-entry")
            # ãƒ‘ã‚¿ãƒ¼ãƒ³â‘¡ ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ¼ãƒå¯¾å¿œ
            if not entry_content:
                entry_content = soup.find("div", class_="entry-content")
            if not entry_content:
                continue

            imgs = entry_content.find_all("img")
            for img in imgs:
                alt = img.get("alt", "").strip()
                src = img.get("src")
                if alt and src:
                    entries.append({"alt": alt, "src": src})
    print(f"ğŸ§© æ¤œå‡ºç”»åƒæ•°: {len(entries)} æš")
    return entries

# ====== äº”åéŸ³ã‚°ãƒ«ãƒ¼ãƒ—åˆ¤å®š ======
def get_aiuo_group(name):
    if not name:
        return "ãã®ä»–"
    first = name[0]
    for group, chars in AIUO_GROUPS.items():
        if first in chars:
            return group
    return "ãã®ä»–"

# ====== ã‚®ãƒ£ãƒ©ãƒªãƒ¼HTMLç”Ÿæˆ ======
def generate_gallery(entries):
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    grouped = {}
    for e in entries:
        grouped.setdefault(e["alt"], []).append(e["src"])

    # å„ã‚­ãƒã‚³ãƒšãƒ¼ã‚¸ç”Ÿæˆ
    for alt, imgs in grouped.items():
        html = f"<h2>{alt}</h2>\n<div class='gallery'>\n"
        for src in imgs:
            html += f'<img src="{src}" alt="{alt}" loading="lazy">\n'
        html += "</div>\n" + SCRIPT_TAG + STYLE_TAG
        safe_name = alt.replace(" ", "_").replace("/", "_")
        with open(f"{OUTPUT_DIR}/{safe_name}.html", "w", encoding="utf-8") as f:
            f.write(html)

    # äº”åéŸ³åˆ¥ãƒšãƒ¼ã‚¸
    aiuo_dict = {k: [] for k in AIUO_GROUPS.keys()}
    for alt in grouped.keys():
        group = get_aiuo_group(alt)
        if group in aiuo_dict:
            aiuo_dict[group].append(alt)

    for group, names in aiuo_dict.items():
        html = f"<h2>{group}ã®ã‚­ãƒã‚³</h2>\n<ul>\n"
        for alt in sorted(names):
            safe_name = alt.replace(" ", "_").replace("/", "_")
            html += f'<li><a href="{safe_name}.html">{alt}</a></li>\n'
        html += "</ul>\n"
        nav_links = []
        for g in AIUO_GROUPS.keys():
            nav_links.append(f"<strong>{g}</strong>" if g == group else f'<a href="{g}.html">{g}</a>')
        html += "<div class='nav'>" + "ï½œ".join(nav_links) + "</div>\n"
        html += SCRIPT_TAG + STYLE_TAG
        with open(f"{OUTPUT_DIR}/{group}.html", "w", encoding="utf-8") as f:
            f.write(html)

    # index.html
    index = "<h2>äº”åéŸ³åˆ¥åˆ†é¡</h2>\n<ul>\n"
    for group in AIUO_GROUPS.keys():
        index += f'<li><a href="{group}.html">{group}</a></li>\n'
    index += "</ul>\n" + SCRIPT_TAG + STYLE_TAG
    with open(f"{OUTPUT_DIR}/index.html", "w", encoding="utf-8") as f:
        f.write(index)

    print(f"âœ… ã‚®ãƒ£ãƒ©ãƒªãƒ¼ãƒšãƒ¼ã‚¸ç”Ÿæˆå®Œäº†ï¼ï¼ˆ{OUTPUT_DIR}/ï¼‰")

# ====== ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ ======
if __name__ == "__main__":
    fetch_hatena_articles()
    entries = fetch_images()
    if entries:
        generate_gallery(entries)
    else:
        print("âš ï¸ ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
